{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O código abaixo foi desenvolvido para a tarefa da disciplina de desenvolvimento avacando de software."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seguintes bibliotecas foram usadas para desenvolver o trabalho:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import caffe\n",
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import urllib2\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Serão necessários alguns arquivos portanto foi utilizada duas varíavies com o diretório dos arquivos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#diretórios onde estão os arquivos\n",
    "dic_root = \"/home/gustavo/Documents/unb/das/trabalho1\"\n",
    "#diretório da caffe\n",
    "caffe_root = \"/home/gustavo/caffe\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Foi desenvolvida uma classe para encapsular o reconhecimento de face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Face:\n",
    "\t\n",
    "\tdef __init__(self,frame=None):\n",
    "\t\tself.faces = None\n",
    "\t\tself.frame = frame\n",
    "\t\tpath = os.path.join(dic_root,\"haarcascade_frontalface_alt.xml\")\n",
    "\t\tself.classifier = cv2.CascadeClassifier(path)\n",
    "\n",
    "\tdef detect(self):\n",
    "\t\theight, width, depth = self.frame.shape\n",
    "\n",
    "\t\t# create grayscale version\n",
    "\t\tgrayscale = cv2.cvtColor(self.frame, cv2.COLOR_BGR2GRAY)\n",
    "\t \n",
    "\t\t# equalize histogram\n",
    "\t\tcv2.equalizeHist(grayscale, grayscale)\n",
    "\n",
    "\t\t# detect objects\n",
    "\t\tDOWNSCALE = 4\n",
    "\t\tminisize = (self.frame.shape[1]/DOWNSCALE,self.frame.shape[0]/DOWNSCALE)\n",
    "\t\tminiframe = cv2.resize(self.frame, minisize)\n",
    "\t\tfaces = self.classifier.detectMultiScale(miniframe)\n",
    "\t\tself.faces = faces\n",
    "\n",
    "\tdef result(self):\n",
    "\t\tif not(self.faces): self.detect()\n",
    "\t\treturn self.faces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma segunda classe foi desenvolvida para encapsular o reconhecimento de classes de animais:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Net:\n",
    "\n",
    "\tdef __init__(self):\n",
    "\t\tmodel_weights = os.path.join(caffe_root, 'models','bvlc_reference_caffenet','bvlc_reference_caffenet.caffemodel')\n",
    "\t\tmodel_def = os.path.join(caffe_root, 'models', 'bvlc_reference_caffenet','deploy.prototxt')\n",
    "\t\tself.net = caffe.Net(model_def,model_weights,caffe.TEST)\n",
    "\t\tmu = np.load(os.path.join(caffe_root, 'python','caffe','imagenet','ilsvrc_2012_mean.npy'))\n",
    "\t\tmu = mu.mean(1).mean(1)  \n",
    "\t\tself.transformer = caffe.io.Transformer({'data': self.net.blobs['data'].data.shape})\n",
    "\t\tself.transformer.set_transpose('data', (2,0,1))\n",
    "\t\tself.transformer.set_mean('data', mu)      \n",
    "\t\tself.transformer.set_raw_scale('data', 255)      \n",
    "\t\tself.transformer.set_channel_swap('data', (2,1,0)) \n",
    "\t\tself.create_labels()\n",
    "\t\tself.loadsynset()\n",
    "\n",
    "\tdef create_labels(self):\n",
    "\t\tlabels_file = os.path.join(caffe_root, 'data','ilsvrc12','synset_words.txt')\n",
    "\t\tself.labels = np.loadtxt(labels_file, str, delimiter='\\t') \n",
    "\t\t\n",
    "\n",
    "\tdef loadsynset(self):\n",
    "\t\tf = open(\"synset_cats\",\"r\")\n",
    "\t\tself.cats = f.read().splitlines()\n",
    "\t\tf.close()\n",
    "\t\tf = open(\"synset_dogs\",\"r\")\n",
    "\t\tself.dogs = f.read().splitlines()\n",
    "\t\tf.close()\n",
    "\n",
    "\n",
    "\tdef predict_imageNet(self,image_filename):\n",
    "\t\timage = caffe.io.load_image(image_filename)\n",
    "\t\tself.net.blobs['data'].data[...] = self.transformer.preprocess('data', image)\n",
    "\n",
    "\t\t# perform classification\n",
    "\t\tself.net.forward()\n",
    "\n",
    "\t\t# obtain the output probabilities\n",
    "\t\toutput_prob = self.net.blobs['prob'].data[0]\n",
    "\n",
    "\t\t# sort top five predictions from softmax output\n",
    "\t\ttop_inds = output_prob.argsort()[::-1][:5]\n",
    "\n",
    "\n",
    "\t\tpredictions = zip(output_prob[top_inds], self.labels[top_inds])\n",
    "\n",
    "\t\treturn predictions\n",
    "\n",
    "\tdef result(self,img):\n",
    "\t\tpredictions = self.predict_imageNet(img)\n",
    "\t\ttotal_dogs = 0\n",
    "\t\ttotal_cats = 0\n",
    "\t\tfor per, cls in predictions:\n",
    "\t\t\tif cls.split()[0] in self.cats:\n",
    "\t\t\t\ttotal_cats += per\n",
    "\t\t\telif cls.split()[0] in self.dogs:\n",
    "\t\t\t\ttotal_dogs += per\t\t\n",
    "\t\treturn total_dogs,total_cats\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma terceira classe foi necessária para gerenciar os tipos de entrada do usuário"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Input:\n",
    "\n",
    "\tFACES = 1\n",
    "\tPREDICTION = 2\n",
    "\tdef __init__(self, load=None):\n",
    "\t\tself.img = None\n",
    "\t\tif(load): self.resolve(load)\n",
    "\n",
    "\tdef resolve(self,load):\n",
    "\t\tif(self.isFile(load)):\n",
    "\t\t\tprint(\"Aqui\")\n",
    "\t\t\tself.fileResolver(load)\t\n",
    "\t\telif(self.isUrl(load)):\n",
    "\t\t\tself.urlResolver(load)\n",
    "\n",
    "\tdef isFile(self,load):\n",
    "\t\treturn os.path.isfile(load)\n",
    "\tdef isUrl(self,load):\n",
    "\t\ttry:\n",
    "\t\t\turllib2.urlopen(load)\n",
    "\t\t\treturn True\n",
    "\t\texcept urllib2.HTTPError, e:\n",
    "\t\t\treturn False\n",
    "\t\texcept urllib2.URLError, e:\n",
    "\t\t\treturn False\n",
    "\t\treturn False\n",
    "\t\t\t\n",
    "\tdef fileResolver(self,load):\n",
    "\t\tself.img = cv2.imread(load)\n",
    "\t\tself.load = load\n",
    "\n",
    "\tdef urlResolver(self,load):\n",
    "\t\timage = urllib.URLopener()\n",
    "\t\tpath = os.path.join(dic_root,\"0000001.jpg\")\n",
    "\t\timage.retrieve(load,path)\n",
    "\t\timage.close()\n",
    "\t\tself.fileResolver(path)\n",
    "\t\treturn None\n",
    "\t\n",
    "\tdef getImage(self,destination):\n",
    "\t\tif(destination == self.FACES):\n",
    "\t\t\treturn self.img\n",
    "\t\telse:\n",
    "\t\t\treturn self.load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main(argv):\n",
    "\tf = Face()\n",
    "\tn = Net()\n",
    "\tif(len(argv) >= 2):\n",
    "\t\td = Input(argv[1])\n",
    "\t\tf.frame = d.getImage(Input.FACES)\n",
    "\t\tfaces = f.result()\n",
    "\t\tdogs,cats = n.result(d.getImage(Input.PREDICTION))\n",
    "\t\tdogs = dogs * 100\n",
    "\t\tcats = cats * 100\n",
    "\t\tprint(\" \".join([\"Foram detectadas \", str(len(faces)), \"faces\",\"probabilidade de felinos:\",str(cats),\"probabilidade de canindos:\",str(dogs)])) \t\n",
    "\t\tprint(\"As coordenadas da(s) face(s) so: \")\n",
    "\t\tfor face in faces:\n",
    "\t\t\tprint(face)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "/home/gustavo/Documents/unb/das/trabalho1/cats.jpg\n",
      "Aqui\n",
      "Foram detectadas  0 faces probabilidade de felinos: 54.1343528777 probabilidade de canindos: 0\n",
      "As coordenadas da(s) face(s) so: \n"
     ]
    }
   ],
   "source": [
    "main([\" \",os.path.join(dic_root,\"cats.jpg\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
