{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import urllib2\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "home_dir = os.getenv(\"HOME\")\n",
    "caffe_root = os.path.join(home_dir, 'caffe')\n",
    "sys.path.insert(0, os.path.join(caffe_root, 'python'))\n",
    "\n",
    "import caffe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NetFace:\n",
    "    \n",
    "    def __init__(self):\n",
    "        path = \"haarcascade_frontalface_alt.xml\"\n",
    "        self.classifier = cv2.CascadeClassifier(path)\n",
    "    def classifierImage(self,miniframe):\n",
    "        return self.classifier.detectMultiScale(miniframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Face:\n",
    "    \n",
    "    def __init__(self,net=NetFace()):\n",
    "        self.net = net\n",
    "\n",
    "    def detect(self,frame):\n",
    "        height, width, depth = frame.shape\n",
    "\n",
    "        # create grayscale version\n",
    "        grayscale = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # equalize histogram\n",
    "        cv2.equalizeHist(grayscale, grayscale)\n",
    "\n",
    "        # detect objects\n",
    "        DOWNSCALE = 4\n",
    "        minisize = (frame.shape[1]/DOWNSCALE,frame.shape[0]/DOWNSCALE)\n",
    "        miniframe = cv2.resize(frame, minisize)\n",
    "        faces = self.net.classifierImage(miniframe)\n",
    "        \n",
    "        # show rectangles on the faces\n",
    "        #if len(faces)>0:\n",
    "        #    for i in faces:\n",
    "        #        x, y, w, h = [ v*DOWNSCALE for v in i ]\n",
    "        #        cv2.rectangle(frame, (x,y), (x+w,y+h), (0,255,0))\n",
    "        #        cv2.imshow('frame',frame)\n",
    "        #        \n",
    "        #        cv2.waitKey(0)\n",
    "        #        \n",
    "        #        print(\"Faces: \", len(faces))\n",
    "        \n",
    "        return faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NetData:\n",
    "\n",
    "    def __init__(self,net,transformer,labels):\n",
    "        self.transformer = transformer\n",
    "        self.labels = labels\n",
    "        self.net = net\n",
    "\n",
    "    def get_transformer(self):\n",
    "        return self.transformer\n",
    "\n",
    "    def get_labels(self):\n",
    "        return self.labels\n",
    "\n",
    "    def get_net(self):\n",
    "        return self.net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Net:\n",
    "\n",
    "    def __init__(self,net,transformer,labels):\n",
    "        self.netData = NetData(net,transformer,labels)\n",
    "        self.loadsynset()\n",
    "        \n",
    "    def loadsynset(self):\n",
    "        f = open(\"synset_cats\",\"r\")\n",
    "        self.cats = f.read().splitlines()\n",
    "        f.close()\n",
    "        \n",
    "        f = open(\"synset_dogs\",\"r\")\n",
    "        self.dogs = f.read().splitlines()\n",
    "        f.close()\n",
    "\n",
    "    def predict_imageNet(self,image_filename):\n",
    "        image = caffe.io.load_image(image_filename)\n",
    "        self.netData.get_net().blobs['data'].data[...] = self.netData.get_transformer().preprocess('data', image)\n",
    "\n",
    "        # perform classification\n",
    "        self.netData.get_net().forward()\n",
    "\n",
    "        # obtain the output probabilities\n",
    "        output_prob = self.netData.get_net().blobs['prob'].data[0]\n",
    "\n",
    "        # sort top five predictions from softmax output\n",
    "        top_inds = output_prob.argsort()[::-1][:5]\n",
    "\n",
    "        predictions = zip(output_prob[top_inds], self.netData.get_labels()[top_inds])\n",
    "\n",
    "        return predictions\n",
    "\n",
    "    def result(self,img):\n",
    "        predictions = self.predict_imageNet(img)\n",
    "        total_dogs = 0\n",
    "        total_cats = 0\n",
    "        \n",
    "        for per, cls in predictions:\n",
    "            if cls.split()[0] in self.cats:\n",
    "                total_cats += per\n",
    "\n",
    "            elif cls.split()[0] in self.dogs:\n",
    "                total_dogs += per\n",
    "        \n",
    "        return total_dogs*100,total_cats*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Input:\n",
    "\n",
    "    FACES = 1\n",
    "    PREDICTION = 2\n",
    "\n",
    "    def __init__(self, load=None):\n",
    "        self.img = None\n",
    "        if(load): self.resolve(load)\n",
    "\n",
    "    def resolve(self,load):\n",
    "        if(self.isFile(load)):\n",
    "            self.fileResolver(load)\t\n",
    "        \n",
    "        elif(self.isUrl(load)):\n",
    "            self.urlResolver(load)\n",
    "\n",
    "    def isFile(self,load):\n",
    "        return os.path.isfile(load)\n",
    "\n",
    "    def isUrl(self,load):\n",
    "        try:\n",
    "            urllib2.urlopen(load)\n",
    "            return True\n",
    "\n",
    "        except urllib2.HTTPError, e:\n",
    "            return False\n",
    "        \n",
    "        except urllib2.URLError, e:\n",
    "            return False\n",
    "\n",
    "        return False\n",
    "\n",
    "    def fileResolver(self,load):\n",
    "        self.img = cv2.imread(load)\n",
    "        self.load = load\n",
    "\n",
    "    def urlResolver(self,load):\n",
    "        image = urllib.URLopener()\n",
    "        path = \"Images\"\n",
    "        image.retrieve(load,path)\n",
    "        image.close()\n",
    "        self.fileResolver(path)\n",
    "        \n",
    "        return None\n",
    "\n",
    "    def getImage(self,destination):\n",
    "        if(destination == self.FACES):\n",
    "            return self.img\n",
    "\n",
    "        else:\n",
    "            return self.load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Output:\n",
    "\n",
    "    def outFaces(self,faces):\n",
    "        if(len(faces) > 0):\n",
    "            print(\"Foram detectadas {0} faces.\").format(str(len(faces)))\n",
    "            print(\"As coordenadas das faces são: \")\n",
    "\n",
    "            for face in faces:\n",
    "                print(face)\n",
    "        \n",
    "        else:\n",
    "            print(\"Não foram encontradas faces.\")\n",
    "\n",
    "        \n",
    "    def outAnimals(self,dogs,cats):\n",
    "        if(dogs > 0):\n",
    "            print(\"A probabilidade de haver cães na imagem é de: {0}%.\").format(str(dogs))\n",
    "\n",
    "        else:\n",
    "            print(\"Não há cães na imagem.\")\n",
    "\n",
    "        if(cats > 0):\n",
    "            print(\"A probabilidade de haver gatos na imagem é de: {0}%.\").format(str(cats))\n",
    "\n",
    "        else:\n",
    "            print(\"Não há gatos na imagem.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main(argv=sys.argv):\n",
    "    mu = np.load(os.path.join(caffe_root, 'python','caffe','imagenet','ilsvrc_2012_mean.npy'))\n",
    "    mu = mu.mean(1).mean(1)  \n",
    "\n",
    "    model_weights = os.path.join(caffe_root, 'models','bvlc_reference_caffenet','bvlc_reference_caffenet.caffemodel')\n",
    "    model_def = os.path.join(caffe_root, 'models', 'bvlc_reference_caffenet','deploy.prototxt')\n",
    "    net = caffe.Net(model_def,model_weights,caffe.TEST)\n",
    "\n",
    "    transformer = caffe.io.Transformer({'data': net.blobs['data'].data.shape})\n",
    "    transformer.set_transpose('data', (2,0,1))\n",
    "    transformer.set_mean('data', mu)      \n",
    "    transformer.set_raw_scale('data', 255)      \n",
    "    transformer.set_channel_swap('data', (2,1,0)) \n",
    "\n",
    "    labels_file = os.path.join(caffe_root, 'data','ilsvrc12','synset_words.txt')\n",
    "    labels = np.loadtxt(labels_file, str, delimiter='\\t') \n",
    "\n",
    "    f = Face()\n",
    "    n = Net(net,transformer,labels)\n",
    "    o = Output()\n",
    "    \n",
    "    if(len(argv) >= 2):\n",
    "        argv.pop(0)\n",
    "    \n",
    "        for arg in argv:\n",
    "            print(arg)\n",
    "            d = Input(arg)\n",
    "            o.outFaces(f.detect(d.getImage(Input.FACES)))\n",
    "            dogs,cats = n.result(d.getImage(Input.PREDICTION))\n",
    "            o.outAnimals(dogs,cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img_dir = 'Images'\n",
    "images = os.listdir(img_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images/Cachorro-1.jpg\n",
      "Não foram encontradas faces.\n",
      "A probabilidade de haver cães na imagem é de: 44.1126599908%.\n",
      "Não há gatos na imagem.\n",
      "\n",
      "\n",
      "Images/Gato-1.jpg\n",
      "Não foram encontradas faces.\n",
      "Não há cães na imagem.\n",
      "A probabilidade de haver gatos na imagem é de: 67.4296088517%.\n",
      "\n",
      "\n",
      "Images/Familia-com-Cachorro.jpg\n",
      "Foram detectadas 3 faces.\n",
      "As coordenadas das faces são: \n",
      "[129  22  31  31]\n",
      "[85 94 45 45]\n",
      "[138  97  64  64]\n",
      "A probabilidade de haver cães na imagem é de: 39.8055158556%.\n",
      "Não há gatos na imagem.\n",
      "\n",
      "\n",
      "Images/Gato-2.jpg\n",
      "Não foram encontradas faces.\n",
      "Não há cães na imagem.\n",
      "A probabilidade de haver gatos na imagem é de: 99.996507098%.\n",
      "\n",
      "\n",
      "Images/Pessoa.jpg\n",
      "Foram detectadas 1 faces.\n",
      "As coordenadas das faces são: \n",
      "[ 34  37 118 118]\n",
      "Não há cães na imagem.\n",
      "Não há gatos na imagem.\n",
      "\n",
      "\n",
      "Images/Familia.jpg\n",
      "Foram detectadas 2 faces.\n",
      "As coordenadas das faces são: \n",
      "[76 12 28 28]\n",
      "[104   8  36  36]\n",
      "Não há cães na imagem.\n",
      "Não há gatos na imagem.\n",
      "\n",
      "\n",
      "Images/Cachorro-2.jpg\n",
      "Foram detectadas 1 faces.\n",
      "As coordenadas das faces são: \n",
      "[18  9 54 54]\n",
      "A probabilidade de haver cães na imagem é de: 6.68247044086%.\n",
      "Não há gatos na imagem.\n",
      "\n",
      "\n",
      "Images/Casal.jpg\n",
      "Foram detectadas 1 faces.\n",
      "As coordenadas das faces são: \n",
      "[55 40 58 58]\n",
      "Não há cães na imagem.\n",
      "Não há gatos na imagem.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for img_file in images:\n",
    "    main([\" \", os.path.join(img_dir, img_file)])\n",
    "    print \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TestFace' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-4d0fd1300693>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0munittest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mTestFace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munittest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTestCase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-4d0fd1300693>\u001b[0m in \u001b[0;36mTestFace\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0msuite\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munittest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTestSuite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTestFace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"test\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                 \u001b[0msuite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddTest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTestFace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'TestFace' is not defined"
     ]
    }
   ],
   "source": [
    "import unittest\n",
    "\n",
    "class TestFace(unittest.TestCase):\n",
    "    f = Face()\n",
    "    o = Output()\n",
    "    img_dir = 'Images'\n",
    "    \n",
    "    def test_more_than_1_face (self):\n",
    "        image = os.path.join(img_dir, 'Familia.jpg')\n",
    "        faces = f.detect(d.getImage(Input.FACES))\n",
    "        \n",
    "        d = Input(image)\n",
    "        o.outFaces(faces)\n",
    "        self.assertEqual(str(len(faces)),2)\n",
    "\n",
    "    if __name__ == \"__main__\":\n",
    "        suite = unittest.TestSuite()\n",
    "    \n",
    "        for method in dir(TestFace):\n",
    "            if method.startswith(\"test\"):\n",
    "                suite.addTest(TestFace(method))\n",
    "        unittest.TextTestRunner().run(suite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
