{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detector de Faces, Gatos e Cachorros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por: Elaine Cristina Meirelles e Gustavo Coelho"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OBS. Todos os membros contribuíram no trabalho. Onde:\n",
    "- Gustavo: refatoração e aplicação do padrão Private Class;\n",
    "- Elaine: refatoração e criação dos testes unitários."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importando as bibliotecas necessárias**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import urllib2\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Detectando diretórios de Início e de Caffe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "home_directory = os.getenv(\"HOME\")\n",
    "caffe_root = os.path.join(home_directory, 'caffe')\n",
    "sys.path.insert(0, os.path.join(caffe_root, 'python'))\n",
    "\n",
    "import caffe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Uma classe de ligação entre o reconhecimento de faces e animais foi criada**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NetFace:\n",
    "    \n",
    "    def __init__(self):\n",
    "        haarcascade_xml = \"haarcascade_frontalface_alt.xml\"\n",
    "        self.classifier = cv2.CascadeClassifier(haarcascade_xml)\n",
    "        \n",
    "    def classifierImage(self,miniframe):\n",
    "        return self.classifier.detectMultiScale(miniframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Além disso, foi desenvolvida uma classe para encapsular o reconhecimento de face**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Face:\n",
    "    \n",
    "    def __init__(self,net=NetFace()):\n",
    "        self.net = net\n",
    "\n",
    "    def detect(self,frame):\n",
    "        height, width, depth = frame.shape\n",
    "\n",
    "        # create grayscale version\n",
    "        grayscale = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # equalize histogram\n",
    "        cv2.equalizeHist(grayscale, grayscale)\n",
    "\n",
    "        # detect objects\n",
    "        DOWNSCALE = 4\n",
    "        minisize = (frame.shape[1]/DOWNSCALE,frame.shape[0]/DOWNSCALE)\n",
    "        miniframe = cv2.resize(frame, minisize)\n",
    "        faces = self.net.classifierImage(miniframe)\n",
    "        \n",
    "        # show rectangles on the faces\n",
    "        #if len(faces)>0:\n",
    "        #    for i in faces:\n",
    "        #        x, y, w, h = [ v*DOWNSCALE for v in i ]\n",
    "        #        cv2.rectangle(frame, (x,y), (x+w,y+h), (0,255,0))\n",
    "        #        cv2.imshow('frame',frame)\n",
    "        #        \n",
    "        #        cv2.waitKey(0)\n",
    "        #        \n",
    "        #        print(\"Faces: \", len(faces))\n",
    "        \n",
    "        return faces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Utilização do Private Class Design Pattern, através da criação de uma classe de dados**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NetData:\n",
    "\n",
    "    def __init__(self,net,transformer,labels):\n",
    "        self.transformer = transformer\n",
    "        self.labels = labels\n",
    "        self.net = net\n",
    "\n",
    "    def get_transformer(self):\n",
    "        return self.transformer\n",
    "\n",
    "    def get_labels(self):\n",
    "        return self.labels\n",
    "\n",
    "    def get_net(self):\n",
    "        return self.net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Uma outra classe foi desenvolvida para encapsular o reconhecimento de classes de animais**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Net:\n",
    "\n",
    "    def __init__(self,net,transformer,labels):\n",
    "        self.netData = NetData(net,transformer,labels)\n",
    "        self.load_synset()\n",
    "        \n",
    "    def load_synset(self):\n",
    "        f = open(\"synset_cats\",\"r\")\n",
    "        self.cats = f.read().splitlines()\n",
    "        f.close()\n",
    "        \n",
    "        f = open(\"synset_dogs\",\"r\")\n",
    "        self.dogs = f.read().splitlines()\n",
    "        f.close()\n",
    "\n",
    "    def predict_imageNet(self,image_filename):\n",
    "        image = caffe.io.load_image(image_filename)\n",
    "        self.netData.get_net().blobs['data'].data[...] = self.netData.get_transformer().preprocess('data', image)\n",
    "\n",
    "        # perform classification\n",
    "        self.netData.get_net().forward()\n",
    "\n",
    "        # obtain the output probabilities\n",
    "        output_prob = self.netData.get_net().blobs['prob'].data[0]\n",
    "\n",
    "        # sort top five predictions from softmax output\n",
    "        top_inds = output_prob.argsort()[::-1][:5]\n",
    "\n",
    "        predictions = zip(output_prob[top_inds], self.netData.get_labels()[top_inds])\n",
    "\n",
    "        return predictions\n",
    "\n",
    "    def result(self,img):\n",
    "        predictions = self.predict_imageNet(img)\n",
    "        total_dogs = 0\n",
    "        total_cats = 0\n",
    "        \n",
    "        for per, cls in predictions:\n",
    "            if cls.split()[0] in self.cats:\n",
    "                total_cats += per\n",
    "\n",
    "            elif cls.split()[0] in self.dogs:\n",
    "                total_dogs += per\n",
    "        \n",
    "        return total_dogs*100,total_cats*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classe necessária para gerenciamento dos tipos de entrada do usuário**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Input:\n",
    "\n",
    "    FACES = 1\n",
    "    PREDICTION = 2\n",
    "\n",
    "    def __init__(self, load=None):\n",
    "        self.img = None\n",
    "        if(load): self.resolve(load)\n",
    "\n",
    "    def resolve(self,load):\n",
    "        if(self.isFile(load)):\n",
    "            self.fileResolver(load)\t\n",
    "        \n",
    "        elif(self.isUrl(load)):\n",
    "            self.urlResolver(load)\n",
    "\n",
    "    def isFile(self,load):\n",
    "        return os.path.isfile(load)\n",
    "\n",
    "    def isUrl(self,load):\n",
    "        try:\n",
    "            urllib2.urlopen(load)\n",
    "            return True\n",
    "\n",
    "        except urllib2.HTTPError, e:\n",
    "            return False\n",
    "        \n",
    "        except urllib2.URLError, e:\n",
    "            return False\n",
    "\n",
    "        return False\n",
    "\n",
    "    def fileResolver(self,load):\n",
    "        self.img = cv2.imread(load)\n",
    "        self.load = load\n",
    "\n",
    "    def urlResolver(self,load):\n",
    "        image = urllib.URLopener()\n",
    "        path = \"Images\"\n",
    "        image.retrieve(load,path)\n",
    "        image.close()\n",
    "        self.fileResolver(path)\n",
    "        \n",
    "        return None\n",
    "\n",
    "    def getImage(self,destination):\n",
    "        if(destination == self.FACES):\n",
    "            return self.img\n",
    "\n",
    "        else:\n",
    "            return self.load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classe responsável pela saída do resultado para o usuário**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Output:\n",
    "\n",
    "    def outFaces(self,faces):\n",
    "        if(len(faces) > 0):\n",
    "            print(\"Foram detectadas {0} faces.\").format(str(len(faces)))\n",
    "            print(\"As coordenadas das faces são: \")\n",
    "\n",
    "            for face in faces:\n",
    "                print(face)\n",
    "        \n",
    "        else:\n",
    "            print(\"Não foram encontradas faces.\")\n",
    "\n",
    "        \n",
    "    def outAnimals(self,dogs,cats):\n",
    "        if(dogs > 0):\n",
    "            print(\"A probabilidade de haver cães na imagem é de: {0}%.\").format(str(dogs))\n",
    "\n",
    "        else:\n",
    "            print(\"Não há cães na imagem.\")\n",
    "\n",
    "        if(cats > 0):\n",
    "            print(\"A probabilidade de haver gatos na imagem é de: {0}%.\").format(str(cats))\n",
    "\n",
    "        else:\n",
    "            print(\"Não há gatos na imagem.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Método principal para rodar a aplicação**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main(argv=sys.argv):\n",
    "    mu = np.load(os.path.join(caffe_root, 'python','caffe','imagenet','ilsvrc_2012_mean.npy'))\n",
    "    mu = mu.mean(1).mean(1)  \n",
    "\n",
    "    model_weights = os.path.join(caffe_root, 'models','bvlc_reference_caffenet','bvlc_reference_caffenet.caffemodel')\n",
    "    model_def = os.path.join(caffe_root, 'models', 'bvlc_reference_caffenet','deploy.prototxt')\n",
    "    net = caffe.Net(model_def,model_weights,caffe.TEST)\n",
    "\n",
    "    transformer = caffe.io.Transformer({'data': net.blobs['data'].data.shape})\n",
    "    transformer.set_transpose('data', (2,0,1))\n",
    "    transformer.set_mean('data', mu)      \n",
    "    transformer.set_raw_scale('data', 255)      \n",
    "    transformer.set_channel_swap('data', (2,1,0)) \n",
    "\n",
    "    labels_file = os.path.join(caffe_root, 'data','ilsvrc12','synset_words.txt')\n",
    "    labels = np.loadtxt(labels_file, str, delimiter='\\t') \n",
    "\n",
    "    f = Face()\n",
    "    n = Net(net,transformer,labels)\n",
    "    o = Output()\n",
    "    \n",
    "    if(len(argv) >= 2):\n",
    "        argv.pop(0)\n",
    "    \n",
    "        for arg in argv:\n",
    "            print(arg)\n",
    "            \n",
    "            d = Input(arg)\n",
    "            o.outFaces(f.detect(d.getImage(Input.FACES)))\n",
    "            \n",
    "            dogs,cats = n.result(d.getImage(Input.PREDICTION))\n",
    "            o.outAnimals(dogs,cats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Listando todas as images existentes na pasta Images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image_directory = 'Images'\n",
    "images = os.listdir(image_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Rodando a aplicação para cada uma das imagens encontradas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images/Cachorro-1.jpg\n",
      "Não foram encontradas faces.\n",
      "A probabilidade de haver cães na imagem é de: 44.1126599908%.\n",
      "Não há gatos na imagem.\n",
      "\n",
      "\n",
      "Images/Gato-1.jpg\n",
      "Não foram encontradas faces.\n",
      "Não há cães na imagem.\n",
      "A probabilidade de haver gatos na imagem é de: 67.4296088517%.\n",
      "\n",
      "\n",
      "Images/Familia-com-Cachorro.jpg\n",
      "Foram detectadas 3 faces.\n",
      "As coordenadas das faces são: \n",
      "[129  22  31  31]\n",
      "[85 94 45 45]\n",
      "[138  97  64  64]\n",
      "A probabilidade de haver cães na imagem é de: 39.8055158556%.\n",
      "Não há gatos na imagem.\n",
      "\n",
      "\n",
      "Images/Gato-2.jpg\n",
      "Não foram encontradas faces.\n",
      "Não há cães na imagem.\n",
      "A probabilidade de haver gatos na imagem é de: 99.996507098%.\n",
      "\n",
      "\n",
      "Images/Pessoa.jpg\n",
      "Foram detectadas 1 faces.\n",
      "As coordenadas das faces são: \n",
      "[ 34  37 118 118]\n",
      "Não há cães na imagem.\n",
      "Não há gatos na imagem.\n",
      "\n",
      "\n",
      "Images/Familia.jpg\n",
      "Foram detectadas 2 faces.\n",
      "As coordenadas das faces são: \n",
      "[76 12 28 28]\n",
      "[104   8  36  36]\n",
      "Não há cães na imagem.\n",
      "Não há gatos na imagem.\n",
      "\n",
      "\n",
      "Images/Cachorro-2.jpg\n",
      "Foram detectadas 1 faces.\n",
      "As coordenadas das faces são: \n",
      "[18  9 54 54]\n",
      "A probabilidade de haver cães na imagem é de: 6.68247044086%.\n",
      "Não há gatos na imagem.\n",
      "\n",
      "\n",
      "Images/Casal.jpg\n",
      "Foram detectadas 1 faces.\n",
      "As coordenadas das faces são: \n",
      "[55 40 58 58]\n",
      "Não há cães na imagem.\n",
      "Não há gatos na imagem.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for image_file in images:\n",
    "    main([\" \", os.path.join(image_directory, image_file)])\n",
    "    print \"\\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importando a biblioteca de teste unitário**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import unittest\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classe de teste para a detecção de faces**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Foram detectadas 1 faces.\n",
      "As coordenadas das faces são: \n",
      "[ 34  37 118 118]\n",
      "Tempo de execução: 0.05\n",
      "\n",
      "Foram detectadas 2 faces.\n",
      "As coordenadas das faces são: \n",
      "[76 12 28 28]\n",
      "[104   8  36  36]\n",
      "Tempo de execução: 0.01\n",
      "\n",
      "Não foram encontradas faces.\n",
      "Tempo de execução: 0.01\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 3 tests in 0.089s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "class TestFace(unittest.TestCase):\n",
    "\n",
    "    def test_1_face_detected (self):\n",
    "        start = timer()\n",
    "        image = os.path.join('Images', 'Pessoa.jpg')\n",
    "        d = Input(image)\n",
    "        \n",
    "        faces = face.detect(d.getImage(Input.FACES))\n",
    "        \n",
    "        output.outFaces(faces)\n",
    "        end =  timer()\n",
    "        print (\"Tempo de execução: %.2f\\n\" % (end-start))\n",
    "        \n",
    "        self.assertEqual(len(faces),1)\n",
    "        \n",
    "    def test_more_than_1_face_detected (self):\n",
    "        start = timer()\n",
    "        image = os.path.join('Images', 'Familia.jpg')\n",
    "        d = Input(image)\n",
    "\n",
    "        faces = face.detect(d.getImage(Input.FACES))\n",
    "        \n",
    "        output.outFaces(faces)\n",
    "        \n",
    "        end =  timer()\n",
    "        print (\"Tempo de execução: %.2f\\n\" % (end-start))\n",
    "        \n",
    "        self.assertEqual(len(faces),2)\n",
    "        \n",
    "    def test_no_face_detected (self):\n",
    "        start = timer()\n",
    "        image = os.path.join('Images', 'Gato-1.jpg')\n",
    "        d = Input(image)\n",
    "        \n",
    "        faces = face.detect(d.getImage(Input.FACES))\n",
    "        \n",
    "        output.outFaces(faces)\n",
    "        \n",
    "        end =  timer()\n",
    "        print (\"Tempo de execução: %.2f\\n\" % (end-start))\n",
    "        \n",
    "        self.assertEqual(len(faces),0)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # instaciating face and output classes\n",
    "    face = Face()\n",
    "    output = Output()\n",
    "        \n",
    "    suite = unittest.TestSuite()\n",
    "    \n",
    "    for method in dir(TestFace):\n",
    "        if method.startswith(\"test\"):\n",
    "            suite.addTest(TestFace(method))\n",
    "    unittest.TextTestRunner().run(suite)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classe de teste para a detecção de gatos e cachorros**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Não há cães na imagem.\n",
      "A probabilidade de haver gatos na imagem é de: 67.4296088517%.\n",
      "Tempo de execução: 1.37\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A probabilidade de haver cães na imagem é de: 44.1126599908%.\n",
      "Não há gatos na imagem.\n",
      "Tempo de execução: 1.35\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Não há cães na imagem.\n",
      "Não há gatos na imagem.\n",
      "Tempo de execução: 1.45\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 3 tests in 4.178s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "class TestAnimal(unittest.TestCase):\n",
    "    \n",
    "    def test_dog_detected(self):\n",
    "        start = timer()\n",
    "        image = os.path.join('Images', 'Cachorro-1.jpg')\n",
    "        d = Input(image)\n",
    "        \n",
    "        dogs,cats = net_class.result(d.getImage(Input.PREDICTION))\n",
    "        \n",
    "        output.outAnimals(dogs,cats)\n",
    "        end =  timer()\n",
    "        print (\"Tempo de execução: %.2f\\n\" % (end-start))\n",
    "        \n",
    "        self.assertGreaterEqual(dogs, 0)\n",
    "        self.assertEqual(cats, 0)\n",
    "        \n",
    "    def test_cat_detected(self):\n",
    "        start = timer()\n",
    "        image = os.path.join('Images', 'Gato-1.jpg')\n",
    "        d = Input(image)\n",
    "        \n",
    "        dogs,cats = net_class.result(d.getImage(Input.PREDICTION))\n",
    "        \n",
    "        output.outAnimals(dogs,cats)\n",
    "        end =  timer()\n",
    "        print (\"Tempo de execução: %.2f\\n\" % (end-start))\n",
    "        \n",
    "        self.assertGreater(cats, 0)\n",
    "        self.assertEqual(dogs, 0)\n",
    "    \n",
    "    def test_no_cat_no_dog_detected(self):\n",
    "        start = timer()\n",
    "        image = os.path.join('Images', 'Familia.jpg')\n",
    "        d = Input(image)\n",
    "        \n",
    "        dogs,cats = net_class.result(d.getImage(Input.PREDICTION))\n",
    "        \n",
    "        output.outAnimals(dogs,cats)\n",
    "        end =  timer()\n",
    "        print (\"Tempo de execução: %.2f\\n\" % (end-start))\n",
    "        \n",
    "        self.assertEqual(dogs, 0)\n",
    "        self.assertEqual(cats, 0)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    mu = np.load(os.path.join(caffe_root, 'python','caffe','imagenet','ilsvrc_2012_mean.npy'))\n",
    "    mu = mu.mean(1).mean(1)  \n",
    "\n",
    "    model_weights = os.path.join(caffe_root, 'models','bvlc_reference_caffenet','bvlc_reference_caffenet.caffemodel')\n",
    "    model_def = os.path.join(caffe_root, 'models', 'bvlc_reference_caffenet','deploy.prototxt')\n",
    "    net = caffe.Net(model_def,model_weights,caffe.TEST)\n",
    "\n",
    "    transformer = caffe.io.Transformer({'data': net.blobs['data'].data.shape})\n",
    "    transformer.set_transpose('data', (2,0,1))\n",
    "    transformer.set_mean('data', mu)      \n",
    "    transformer.set_raw_scale('data', 255)      \n",
    "    transformer.set_channel_swap('data', (2,1,0)) \n",
    "\n",
    "    labels_file = os.path.join(caffe_root, 'data','ilsvrc12','synset_words.txt')\n",
    "    labels = np.loadtxt(labels_file, str, delimiter='\\t') \n",
    "\n",
    "    # instanciating Net and Output\n",
    "    net_class = Net(net,transformer,labels)\n",
    "    output = Output()\n",
    "\n",
    "    suite = unittest.TestSuite()\n",
    "\n",
    "    for method in dir(TestAnimal):\n",
    "        if method.startswith(\"test\"):\n",
    "            suite.addTest(TestAnimal(method))\n",
    "    unittest.TextTestRunner().run(suite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
